# Machine Learning

> 吴雨婷
>
> ytwu1@bjtu.edu.cn

## 0. 课程

* 课程目标

* 主要内容
  * 有监督学习过渡到无监督学习

* 考核方式
  * 20%作业 + 30%实验 + 50%考试(半开卷)
  * 8次小作业
  * 半开卷: 能带一张A4纸

* 答疑
  * 周一下午 16:10-18:00
  * YF706

## 1. 绪论

### 1.1 背景

* 概念
  * 计算机利用经验改善系统自身性能的行动
  * 三个重要的理论问题
    * 一致: 样本集和测试集i.i.d
    * 划分: 在样本空间内寻找决策分界面
    * 泛化: 对未知样本的判断能力
    * i.i.d: 独立同分布

* 范围

* 应用

* 发展历史

* 知名人物
  * 深度学习三巨头

### 1.2 基本知识

* 机器学习的类型
  * 监督学习
  * 无监督学习
  * 强化学习

* 基本术语
  * (略)
  * **假设空间**
    * 定义：所有属性的可能性(可能取值)组成的空间
    * 每维属性还包含一个通配符，并且存在空集
    * 所以比如3个属性，每个属性有3种取值
    * 则 **总假设空间大小** 为 4\*4\*4 + 1 = 65
  * **版本空间**
    * 定义：多个与训练集一致的 **假设**
  * **归纳偏好**
    * 定义：学习过程中对某种类型假设的偏好
    * 每种算法必有其归纳偏好
    > "奥卡姆剃刀" 原则

* No Free Lunch: 每个算法都有其优势
  * 西瓜书的特例证明，假设 **所有问题出现的概率相同**，则得到对于二分类问题：**总误差和学习算法无关**
    * 但现实中，**问题出现概率并不同**，所以每个算法都有它的优势

* 统计学习 三要素
  * 模型
  * 策略
    * 损失函数 Loss Function
    * 风险函数 Risk Function
  * 算法

### 1.3 机器学习 开发流程

* 一般步骤
  * 数据收集
  * 数据清洗
  * 特征工程
  * 数据建模

### 1.4 模型的评估和选择

* 指标
  * Error Rate
  * Accuracy   = (TP + FN) / (TP + FN + FP + TN)
  * Precision  = TP / (TP + FP)
  * Recall     = TP / (TP + FN)
  * Loss

* 拟合问题
  * 过拟合
    * 解决方法：优化目标加正则项、early stop
  * 欠拟合

* 评估方法
  * 留出法
  * 交叉验证法
    * 如：10折交叉验证
  * 留一法
  * 自助法

* 性能度量
  * 回归任务
    * 最常用的是：均方误差
      * $ E(f;D) = \Large \frac{1}{m} \sum_{i=1}^{m}(f(x_i)-y_i)^2 $
  * 分类任务
    * 最常用的是：ErrorRate，Accuracy
    * Precision 与 Recall 往往是矛盾的
  * **P-R 曲线**
    * 算出所有样本的正例概率，然后使用这些正例概率分别作为阈值，得到混淆矩阵
    * 将每个混淆矩阵转换为一个点对 (R, P)
    * 将这些点绘制在平面直角坐标系上，得到 P-R 曲线
    * 将曲线上 "P=R" 的点，称为 **平衡点(Break-event Point)**
    * **平衡点**，用于衡量P-R曲线有交叉的分类器性能高低
    * ![1](./Notes/23.9.11.1.png)
  * **F1度量** (F1-Score)
    * $ F1 = \Large \frac{2 \times P \times R}{P + R} \normalsize = \Large \frac{2 \times TP}{样例总数 + TP - TN} $
    * $ F_{\beta} = Large \frac{(1+\beta^2)\times P \times R}{(\beta^2 \times P) + R} $
      * 当 $ \beta = 1 $ 时，标准 $F_1$
      * 当 $ \beta > 1 $ 时，偏重recall（如逃犯信息检索）
      * 当 $ \beta < 1 $ 时，偏重precision（如商品推荐系统）
  * **macro-F1**
    * 当需要对多个混淆矩阵做性能度量时，可以使用 **macro-F1**
    * **macro-P**: $P_i$ 的均值
    * **macro-R**: $R_i$ 的均值
    * **macro-F1**: 通过 macro-P 和 macro-R 算出 macro-F1
    * 先取均值，再计算 $F1$
  * **micro-F1**
    * 先计算出 $F1_i$，再取均值
  * **ROC图**
    * 类似P-R曲线，先对样本排序，再将样本逐个作为阈值得到多个点
    * 纵轴: $ TPR = \Large \frac{TP}{TP+FN} $
      * $ FNR = 1 - TPR $
    * 横轴: $ FPR = \Large \frac{FP}{FP+TN} $
      * $ TNR = 1 - FPR $
    * 阈值从高到低时，设前一个点为(x, y)，则下一个点为 $ (x, y + \frac{1}{m^+}) $ 或 $ (x + \frac{1}{m^-}, y) $
      * 这个性质可以用于加速图像的绘制
    * AUC: Area Under Curve
      * 曲线下方面积，用于衡量样本预测的排序质量（正样本尽量靠前，负样本尽量靠后）
    * ![roc](./Notes/23.9.11.2.png)
    * 问题：为什么阈值要取样本的确切点呢？
      * 因为连续值没有意义，样本是离散的！
  * 代价敏感错误率
    * 设定“代价矩阵”，令 $cost_{ij}$ 表示将第 $i$ 类样本预测成 $j$ 的代价
    * 就是给错误率加权
    * $cost_{01}$：把正例预测成负例的代价
  * **代价曲线**
    * 横轴：取值为 [0, 1] 的正例概率代价
      * $ P(+)cost = \Large \frac{p*cost_{01}}{p*cost_{01} + (1-p)*cost_{10}} $
      * $p$：随机抽一个样本，正例概率（比例）
      * $p*cost_{01}$：正例预测错的期望花费
      * $p*cost_{01} + (1-p)*cost_{10}$：预测错的期望花费
    * 纵轴：取值为 [0, 1] 的归一化代价
      * $ cost_{norm} = \Large \frac{FNR * p * cost_{01} + FPR * (1-p) * cost_{10}}{p*cost_{01} + (1-p)*cost_{10}} $
      * 实际上，就是 $ 正例预测错的概率 * 正例概率代价 + 负例预测错的概率 * 负例概率代价 $
    * 如何绘制代价曲线
      * 设 ROC上的一个点为 (FPR, TPR)
      * 则 将该点转化为代价曲线上的一条线段
      * $ x = P(+)cost $
      * $ y = FNR * x + FPR * (1 - x) $
      * $y$ 显然是关于 $x$ 的一条直线，但 $x$ 有取值范围，所以这是一条线段
    * 取所有线段下方面积的交集，即为 **所以条件下，该学习器的期望总体代价**
      * 所有线段产生贡献的部分，称为 **代价曲线**
      * ![代价曲线](./Notes/23.9.11.3.png)
    * 作用
      * 可以或得到每种正例概率代价下，最优的阈值
  * 偏差 与 方差
    * 方差 Variance
    * 偏差 Bias
    * ![偏差和方差](./Notes/23.9.11.4.png)

